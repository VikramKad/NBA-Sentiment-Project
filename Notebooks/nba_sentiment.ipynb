{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Sentiment Analysis\n",
    "\n",
    "This notebook processes Reddit data for NBA players, performs sentiment analysis, and merges it with their game statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install and import required libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ensure VADER lexicon is available\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "    print(\"VADER lexicon already downloaded\")\n",
    "except LookupError:\n",
    "    print(\"Downloading VADER lexicon...\")\n",
    "    nltk.download('vader_lexicon')\n",
    "    print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "# Base directory where your 'new' folder containing 'reddit_data' and 'player_stats' is\n",
    "BASE_DATA_DIR = 'data/new/'\n",
    "REDDIT_DATA_DIR = os.path.join(BASE_DATA_DIR, 'reddit_data')\n",
    "PLAYER_STATS_DIR = os.path.join(BASE_DATA_DIR, 'player_stats')\n",
    "OUTPUT_DIR = os.path.join(BASE_DATA_DIR, 'processed_data')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# List of player file slugs\n",
    "PLAYER_SLUGS = [\n",
    "    \"anthony_edwards\",\n",
    "    \"donovan_mitchell\",\n",
    "    \"giannis_antetokounmpo\",\n",
    "    \"jalen_brunson\",\n",
    "    \"lebron_james\",\n",
    "    \"luka_doncic\",\n",
    "    \"shai_gilgeous-alexander\",\n",
    "    \"stephen_curry\"\n",
    "]\n",
    "\n",
    "# Seasons for game logs\n",
    "SEASONS = [\"2022\", \"2023\", \"2024\"]\n",
    "\n",
    "# Initialize the Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Reddit Data\n",
    "\n",
    "Let's look at one player's Reddit data to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load sample Reddit data for one player\n",
    "sample_player = \"lebron_james\"\n",
    "reddit_file_path = os.path.join(REDDIT_DATA_DIR, f\"{sample_player}_reddit_mentions.csv\")\n",
    "\n",
    "try:\n",
    "    sample_reddit_df = pd.read_csv(reddit_file_path)\n",
    "    print(f\"Loaded {len(sample_reddit_df)} Reddit mentions for {sample_player}.\")\n",
    "    print(f\"\\nColumn names: {sample_reddit_df.columns.tolist()}\")\n",
    "    display(sample_reddit_df.head(2))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Reddit data for {sample_player}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Player Data Function\n",
    "\n",
    "This function handles the processing for a single player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_player_data(player_slug, target_season):\n",
    "    \"\"\"\n",
    "    Loads Reddit data and player stats, performs sentiment analysis,\n",
    "    aggregates sentiment, merges data, and saves the result.\n",
    "    \"\"\"\n",
    "    logging.info(f\"--- Processing player: {player_slug} for season {target_season} ---\")\n",
    "\n",
    "    # --- 1. Load Reddit Data ---\n",
    "    reddit_file_path = os.path.join(REDDIT_DATA_DIR, f\"{player_slug}_reddit_mentions.csv\")\n",
    "    if not os.path.exists(reddit_file_path):\n",
    "        logging.error(f\"Reddit mentions file not found for {player_slug}: {reddit_file_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        reddit_df = pd.read_csv(reddit_file_path)\n",
    "        logging.info(f\"Loaded {len(reddit_df)} Reddit mentions for {player_slug}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading Reddit data for {player_slug}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if reddit_df.empty:\n",
    "        logging.warning(f\"Reddit data for {player_slug} is empty. Skipping further processing for this player.\")\n",
    "        return None\n",
    "\n",
    "    # --- 2. Sentiment Scoring ---\n",
    "    # Concatenate title, body, and comments for sentiment analysis\n",
    "    text_columns = ['post_title', 'post_body', 'scraped_comments_sample']\n",
    "    for col in text_columns:\n",
    "        if col not in reddit_df.columns:\n",
    "            logging.warning(f\"Column '{col}' not found in Reddit data for {player_slug}. Will use empty string.\")\n",
    "            reddit_df[col] = \"\" # Add empty column if missing to prevent error\n",
    "\n",
    "    reddit_df['combined_text'] = reddit_df[text_columns].fillna('').agg(' '.join, axis=1)\n",
    "    \n",
    "    # Apply VADER sentiment analysis\n",
    "    try:\n",
    "        reddit_df['compound_sentiment'] = reddit_df['combined_text'].apply(\n",
    "            lambda txt: sia.polarity_scores(str(txt))['compound'] # Ensure txt is string\n",
    "        )\n",
    "        logging.info(f\"Calculated compound sentiment for {player_slug}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during sentiment scoring for {player_slug}: {e}\")\n",
    "        reddit_df['compound_sentiment'] = 0.0 # Fallback to neutral\n",
    "\n",
    "    # --- 3. Aggregate Sentiment per game_date_reference ---\n",
    "    if 'game_date_reference' not in reddit_df.columns:\n",
    "        logging.error(f\"'game_date_reference' column missing in Reddit data for {player_slug}.\")\n",
    "        return None\n",
    "\n",
    "    daily_sentiment = reddit_df.groupby('game_date_reference').agg(\n",
    "        mean_sentiment=('compound_sentiment', 'mean'),\n",
    "        positive_sentiment_ratio=('compound_sentiment', lambda x: (x > 0.05).mean()), # Standard VADER threshold for positive\n",
    "        negative_sentiment_ratio=('compound_sentiment', lambda x: (x < -0.05).mean()),# Standard VADER threshold for negative\n",
    "        mention_count=('compound_sentiment', 'size')\n",
    "    ).reset_index()\n",
    "    logging.info(f\"Aggregated daily sentiment for {player_slug}.\")\n",
    "\n",
    "    # --- 4. Load Player Game Stats ---\n",
    "    stats_file_path = os.path.join(PLAYER_STATS_DIR, f\"season_{target_season}\", f\"{player_slug}_gamelog.csv\")\n",
    "    if not os.path.exists(stats_file_path):\n",
    "        logging.error(f\"Player stats file not found for {player_slug}, season {target_season}: {stats_file_path}\")\n",
    "        return None \n",
    "        \n",
    "    try:\n",
    "        stats_df = pd.read_csv(stats_file_path)\n",
    "        logging.info(f\"Loaded {len(stats_df)} game log entries for {player_slug}, season {target_season}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading player stats for {player_slug}, season {target_season}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if 'GAME_DATE' not in stats_df.columns:\n",
    "        logging.error(f\"'GAME_DATE' column missing in stats data for {player_slug}, season {target_season}.\")\n",
    "        return None\n",
    "\n",
    "    # --- 5. Merge Sentiment with Stats ---\n",
    "    # Convert GAME_DATE in stats_df to 'YYYY-MM-DD' string format to match daily_sentiment\n",
    "    try:\n",
    "        stats_df['game_date_reference'] = pd.to_datetime(stats_df['GAME_DATE'], format='%b %d, %Y').dt.strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error converting GAME_DATE format for {player_slug}: {e}. Check if format string is correct.\")\n",
    "        try:\n",
    "            logging.warning(f\"Attempting general date parsing for {player_slug} due to format error.\")\n",
    "            stats_df['game_date_reference'] = pd.to_datetime(stats_df['GAME_DATE']).dt.strftime('%Y-%m-%d')\n",
    "        except Exception as e_gen:\n",
    "            logging.error(f\"General date parsing also failed for {player_slug}: {e_gen}. Cannot proceed with merge.\")\n",
    "            return None\n",
    "\n",
    "    # Merge stats with daily sentiment\n",
    "    merged_df = pd.merge(stats_df, daily_sentiment, on='game_date_reference', how='left')\n",
    "    \n",
    "    # Fill NaN values for sentiment columns (for game days with no Reddit mentions)\n",
    "    sentiment_cols_to_fill = ['mean_sentiment', 'positive_sentiment_ratio', 'negative_sentiment_ratio', 'mention_count']\n",
    "    fill_values = {\n",
    "        'mean_sentiment': 0.0,  # Neutral sentiment\n",
    "        'positive_sentiment_ratio': 0.0,\n",
    "        'negative_sentiment_ratio': 0.0,\n",
    "        'mention_count': 0      # Zero mentions\n",
    "    }\n",
    "    for col in sentiment_cols_to_fill:\n",
    "        if col in merged_df.columns:\n",
    "            merged_df[col] = merged_df[col].fillna(fill_values.get(col, 0))\n",
    "        else:\n",
    "            merged_df[col] = fill_values.get(col, 0)\n",
    "\n",
    "    logging.info(f\"Merged stats and sentiment for {player_slug}. Resulting shape: {merged_df.shape}\")\n",
    "\n",
    "    # --- 6. Save Processed Data ---\n",
    "    output_file_path = os.path.join(OUTPUT_DIR, f\"{player_slug}_stats_plus_sentiment_{target_season}.csv\")\n",
    "    try:\n",
    "        merged_df.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "        logging.info(f\"âœ… Successfully saved processed data to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving processed data for {player_slug}: {e}\")\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All Players\n",
    "\n",
    "Now let's process all players for all seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all_players_merged_data = {}\n",
    "\n",
    "for season in SEASONS:\n",
    "    print(f\"\\n==== Processing Season {season} ====\\n\")\n",
    "    \n",
    "    for slug in PLAYER_SLUGS:\n",
    "        processed_df = process_player_data(slug, season)\n",
    "        if processed_df is not None:\n",
    "            all_players_merged_data[f\"{slug}_{season}\"] = processed_df\n",
    "            print(f\"Finished processing for {slug} (Season {season}).\")\n",
    "        else:\n",
    "            print(f\"Processing failed or resulted in no data for {slug} (Season {season}).\")\n",
    "            \n",
    "print(\"\\n--- All players processed. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization Examples\n",
    "\n",
    "Let's create some visualizations of our processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example 1: Sentiment vs. Performance for a single player\n",
    "def plot_sentiment_vs_performance(player_slug, season, metric='PTS'):\n",
    "    \"\"\"Plot the relationship between sentiment and a performance metric\"\"\"\n",
    "    key = f\"{player_slug}_{season}\"\n",
    "    if key not in all_players_merged_data:\n",
    "        print(f\"No data found for {player_slug} in season {season}\")\n",
    "        return\n",
    "        \n",
    "    df = all_players_merged_data[key].copy()\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Plot 1: Performance over time\n",
    "    ax1.plot(range(len(df)), df[metric], 'o-', color='blue', label=metric)\n",
    "    ax1.set_ylabel(metric, fontsize=12)\n",
    "    ax1.set_title(f\"{player_slug.replace('_', ' ').title()}: {metric} per Game (Season {season})\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot 2: Sentiment over time\n",
    "    ax2.plot(range(len(df)), df['mean_sentiment'], 'o-', color='green', label='Mean Sentiment')\n",
    "    ax2.fill_between(range(len(df)), 0, df['mean_sentiment'], \n",
    "                    where=(df['mean_sentiment'] > 0), color='green', alpha=0.3)\n",
    "    ax2.fill_between(range(len(df)), 0, df['mean_sentiment'], \n",
    "                    where=(df['mean_sentiment'] < 0), color='red', alpha=0.3)\n",
    "    ax2.set_ylabel('Sentiment Score', fontsize=12)\n",
    "    ax2.set_xlabel('Game Number', fontsize=12)\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.set_title(f\"Mean Reddit Sentiment Score\")\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation analysis\n",
    "    corr = df[[metric, 'mean_sentiment']].corr().iloc[0,1]\n",
    "    print(f\"Correlation between {metric} and sentiment: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example 2: Compare sentiment across players\n",
    "def compare_player_sentiments(season):\n",
    "    \"\"\"Compare sentiment distributions across players for a given season\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for slug in PLAYER_SLUGS:\n",
    "        key = f\"{slug}_{season}\"\n",
    "        if key in all_players_merged_data:\n",
    "            data.append(all_players_merged_data[key]['mean_sentiment'])\n",
    "            labels.append(slug.replace('_', ' ').title())\n",
    "    \n",
    "    if not data:\n",
    "        print(f\"No data found for season {season}\")\n",
    "        return\n",
    "        \n",
    "    plt.boxplot(data, labels=labels, showfliers=True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Sentiment Score')\n",
    "    plt.title(f\"Sentiment Distribution Comparison (Season {season})\")\n",
    "    plt.axhline(y=0, color='red', linestyle='--', alpha=0.3)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Let's try the visualization for a player\n",
    "# Run this after you have processed the data\n",
    "# Replace with your actual player and season\n",
    "try:\n",
    "    player_to_plot = \"lebron_james\"\n",
    "    season_to_plot = \"2023\"\n",
    "    plot_sentiment_vs_performance(player_to_plot, season_to_plot, 'PTS')\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare sentiments across players\n",
    "# Run this after you have processed the data\n",
    "try:\n",
    "    compare_player_sentiments(\"2023\")\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting comparison: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Analysis and Insights\n",
    "\n",
    "Here we can analyze the relationship between sentiment and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_correlations(player_slug, season):\n",
    "    \"\"\"Calculate correlations between sentiment and various performance metrics\"\"\"\n",
    "    key = f\"{player_slug}_{season}\"\n",
    "    if key not in all_players_merged_data:\n",
    "        print(f\"No data found for {player_slug} in season {season}\")\n",
    "        return None\n",
    "        \n",
    "    df = all_players_merged_data[key]\n",
    "    \n",
    "    # Potential performance metrics\n",
    "    potential_metrics = ['PTS', 'AST', 'REB', 'STL', 'BLK', 'TOV', 'PLUS_MINUS', 'MIN']\n",
    "    available_metrics = [col for col in potential_metrics if col in df.columns]\n",
    "    \n",
    "    if not available_metrics:\n",
    "        print(f\"No known performance metrics found for {player_slug}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = []\n",
    "    for metric in available_metrics:\n",
    "        corr = df[['mean_sentiment', metric]].corr().iloc[0,1]\n",
    "        correlations.append({'Metric': metric, 'Correlation': corr})\n",
    "    \n",
    "    corr_df = pd.DataFrame(correlations).sort_values('Correlation', ascending=False)\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate and display correlations for a player\n",
    "# Replace with your actual player and season\n",
    "try:\n",
    "    player_to_analyze = \"lebron_james\"\n",
    "    season_to_analyze = \"2023\"\n",
    "    \n",
    "    corr_results = calculate_correlations(player_to_analyze, season_to_analyze)\n",
    "    if corr_results is not None:\n",
    "        print(f\"Correlations between Reddit sentiment and performance metrics for {player_to_analyze.replace('_', ' ').title()} (Season {season_to_analyze}):\")\n",
    "        display(corr_results)\n",
    "        \n",
    "        # Visualization of correlations\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(corr_results['Metric'], corr_results['Correlation'], color=['g' if x > 0 else 'r' for x in corr_results['Correlation']])\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.title(f\"Correlation between Sentiment and Performance\\n{player_to_analyze.replace('_', ' ').title()} (Season {season_to_analyze})\")\n",
    "        plt.ylabel('Correlation Coefficient')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing correlations: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}